import openai
import json
import os


def load_config(path):
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def run_gpt_api(prompt, text, api_key):
    """OpenAI APIã‚’å®Ÿè¡Œã—ã¦çµæœã‚’å–å¾—ã™ã‚‹"""
    client = openai.OpenAI(api_key=api_key)
    full_prompt = f"{prompt}\n\n{text}"  # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆ

    try:
        response = client.chat.completions.create(
            model="gpt-4o",  # æœ€æ–°ãƒ¢ãƒ‡ãƒ«æ¨å¥¨ã€å¿…è¦ã«å¿œã˜ã¦å¤‰æ›´
            messages=[
                {
                    "role": "system",
                    "content": "ã‚ãªãŸã¯æœ‰èƒ½ãªæ—¥æœ¬èªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚æŒ‡ç¤ºã«å¾“ã£ã¦ã€æ­£ç¢ºã«ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚",
                },
                {"role": "user", "content": full_prompt},
            ],
            max_tokens=1500,  # å‡ºåŠ›ã«å¿œã˜ã¦èª¿æ•´ (åˆ†é¡ã¨æœ¬æ–‡ã§ååˆ†ãªé•·ã•ã‚’ç¢ºä¿)
            temperature=0.2,  # å†ç¾æ€§ã‚’é«˜ã‚ã‚‹ãŸã‚ã«ä½ã‚ã®æ¸©åº¦è¨­å®š
            # top_p=1.0,
            # frequency_penalty=0.0,
            # presence_penalty=0.0,
        )
        return response.choices[0].message.content.strip()
    except openai.APIConnectionError as e:
        print(f"âŒ OpenAI APIæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
    except openai.RateLimitError as e:
        print(f"âŒ OpenAI APIãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼: {e}")
    except openai.APIStatusError as e:
        print(f"âŒ OpenAI APIã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚¨ãƒ©ãƒ¼ (HTTP {e.status_code}): {e.response}")
    except Exception as e:
        print(f"âŒ OpenAI APIå‘¼ã³å‡ºã—ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}")
    return None  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯Noneã‚’è¿”ã™


def parse_gpt_output(gpt_response_text):
    """GPTã®å‡ºåŠ›ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦åˆ†é¡ã¨æ•´å½¢æ¸ˆã¿æœ¬æ–‡ã‚’å–å¾—ã™ã‚‹"""
    final_classification = "æ¡ˆä»¶æŠ•ç¨¿"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ã€Œæ¡ˆä»¶æŠ•ç¨¿ã€ã¨ã™ã‚‹
    formatted_text = ""

    if not gpt_response_text:
        return {
            "classification": final_classification,
            "formatted_text": formatted_text,
        }

    lines = [
        line.strip() for line in gpt_response_text.strip().split("\n") if line.strip()
    ]

    classification_tag_found = False  # ã€åˆ†é¡ã€‘ï¼šã‚¿ã‚°ãŒè¦‹ã¤ã‹ã£ãŸã‹
    text_tag_found = False  # ã€æ•´å½¢å¾ŒOCRã€‘ï¼šã‚¿ã‚°ãŒè¦‹ã¤ã‹ã£ãŸã‹

    parsed_classification_value_from_gpt = None  # GPTãŒè¿”ã—ãŸåˆ†é¡ã®å€¤ã‚’ä¸€æ™‚çš„ã«ä¿æŒ

    # ã¾ãšã€åˆ†é¡ã€‘ï¼šã‚’æ¢ã™
    for i, line in enumerate(lines):
        if line.startswith("ã€åˆ†é¡ã€‘ï¼š"):
            classification_tag_found = True
            classification_content = line.replace("ã€åˆ†é¡ã€‘ï¼š", "").strip()

            # ã€åˆ†é¡ã€‘ï¼šã¨ã€æ•´å½¢å¾ŒOCRã€‘ï¼šãŒåŒã˜è¡Œã«ã‚ã‚‹å ´åˆ
            if "ã€æ•´å½¢å¾ŒOCRã€‘ï¼š" in classification_content:
                parts = classification_content.split("ã€æ•´å½¢å¾ŒOCRã€‘ï¼š", 1)
                parsed_classification_value_from_gpt = parts[0].strip()
                if len(parts) > 1:
                    formatted_text = parts[1].strip()
                text_tag_found = True
                break  # ä¸¡æ–¹è¦‹ã¤ã‹ã£ãŸã®ã§ã€ã“ã®ãƒ–ãƒ­ãƒƒã‚¯ã®å‡¦ç†ã¯çµ‚äº†
            else:
                parsed_classification_value_from_gpt = classification_content
                # åˆ†é¡ãŒè¦‹ã¤ã‹ã£ãŸã®ã§ã€æ®‹ã‚Šã®è¡Œã‹ã‚‰æ•´å½¢å¾ŒOCRã‚’æ¢ã™
                text_lines_collector = []
                ocr_tag_started_in_this_block = False
                for j in range(i + 1, len(lines)):
                    sub_line = lines[j]
                    if sub_line.startswith("ã€æ•´å½¢å¾ŒOCRã€‘ï¼š"):
                        text_lines_collector.append(
                            sub_line.replace("ã€æ•´å½¢å¾ŒOCRã€‘ï¼š", "").strip()
                        )
                        ocr_tag_started_in_this_block = True
                        text_tag_found = True
                    elif ocr_tag_started_in_this_block:  # æ•´å½¢å¾ŒOCRãŒé–‹å§‹ã•ã‚ŒãŸå¾Œã®è¡Œ
                        if sub_line.startswith(
                            "ã€åˆ†é¡ã€‘ï¼š"
                        ):  # æ¬¡ã®åˆ†é¡ãŒå§‹ã¾ã£ãŸã‚‰çµ‚äº†
                            break
                        text_lines_collector.append(sub_line)
                    elif not ocr_tag_started_in_this_block and sub_line.startswith(
                        "ã€åˆ†é¡ã€‘ï¼š"
                    ):
                        # ã“ã®åˆ†é¡ã«å¯¾å¿œã™ã‚‹æ•´å½¢å¾ŒOCRãŒè¦‹ã¤ã‹ã‚‹å‰ã«æ¬¡ã®åˆ†é¡ãŒå§‹ã¾ã£ãŸ
                        break
                if text_lines_collector:
                    formatted_text = "\n".join(text_lines_collector).strip()
                break  # ã€åˆ†é¡ã€‘ï¼šè¡Œã®å‡¦ç†ãŒçµ‚ã‚ã£ãŸã‚‰ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹

    # ã€åˆ†é¡ã€‘ï¼šã‚¿ã‚°ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸã‹ã€ã¾ãŸã¯ã€æ•´å½¢å¾ŒOCRã€‘ï¼šãŒã¾ã è¦‹ã¤ã‹ã£ã¦ã„ãªã„å ´åˆã€
    # ã€æ•´å½¢å¾ŒOCRã€‘ï¼šã‚¿ã‚°ã‚’ç‹¬ç«‹ã—ã¦æ¢ã™
    if not text_tag_found:
        text_lines_collector = []
        ocr_tag_started_independently = False
        for i, line in enumerate(lines):  # å†åº¦å…¨è¡Œã‚’ãƒã‚§ãƒƒã‚¯
            if line.startswith("ã€æ•´å½¢å¾ŒOCRã€‘ï¼š"):
                text_lines_collector.append(line.replace("ã€æ•´å½¢å¾ŒOCRã€‘ï¼š", "").strip())
                ocr_tag_started_independently = True
                text_tag_found = True  # ã€æ•´å½¢å¾ŒOCRã€‘ï¼šã‚¿ã‚°ãŒè¦‹ã¤ã‹ã£ãŸã“ã¨ã‚’è¨˜éŒ²
            elif ocr_tag_started_independently:
                # æ•´å½¢å¾ŒOCRãŒé–‹å§‹ã•ã‚ŒãŸå¾Œã§ã€æ¬¡ã®ã€åˆ†é¡ã€‘ï¼šã‚„ã€æ•´å½¢å¾ŒOCRã€‘ï¼šãŒæ¥ãŸã‚‰ã€ãã“ã¾ã§ãŒæ•´å½¢å¾ŒOCR
                if line.startswith("ã€åˆ†é¡ã€‘ï¼š") or line.startswith("ã€æ•´å½¢å¾ŒOCRã€‘ï¼š"):
                    break
                text_lines_collector.append(line)
        if text_lines_collector:
            formatted_text = "\n".join(text_lines_collector).strip()

    # GPTã‹ã‚‰å–å¾—ã—ãŸåˆ†é¡ã®å€¤ã«åŸºã¥ã„ã¦æœ€çµ‚çš„ãªåˆ†é¡ã‚’æ±ºå®š
    if parsed_classification_value_from_gpt == "è³ªå•å›ç­”":
        final_classification = "è³ªå•å›ç­”"
    elif (
        parsed_classification_value_from_gpt
        and parsed_classification_value_from_gpt not in ["è³ªå•å›ç­”", "æ¡ˆä»¶æŠ•ç¨¿"]
    ):
        # ã€Œã‚¹ãƒ«ãƒ¼ãƒ‡ãƒ¼ã‚¿ã€ã‚„ãã®ä»–ã®äºˆæœŸã—ãªã„åˆ†é¡ãŒè¿”ã£ã¦ããŸå ´åˆ
        print(
            f"âš ï¸ GPTã«ã‚ˆã‚‹åˆ†é¡çµæœ '{parsed_classification_value_from_gpt}' ã¯ã€Œæ¡ˆä»¶æŠ•ç¨¿ã€ã¨ã—ã¦æ‰±ã„ã¾ã™ã€‚"
        )
        # final_classification ã¯æ—¢ã«ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ "æ¡ˆä»¶æŠ•ç¨¿"
    # parsed_classification_value_from_gpt ãŒ "æ¡ˆä»¶æŠ•ç¨¿" ã¾ãŸã¯ None ã®å ´åˆã€final_classification ã¯ "æ¡ˆä»¶æŠ•ç¨¿" ã®ã¾ã¾

    # ã©ã†ã—ã¦ã‚‚ãƒ‘ãƒ¼ã‚¹ã§ããªã„å ´åˆï¼ˆã‚¿ã‚°ãŒå…¨ãè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆï¼‰ã€GPTã®å‡ºåŠ›ã‚’ãã®ã¾ã¾æ•´å½¢å¾ŒOCRã¨ã—ã¦æ‰±ã†
    if not classification_tag_found and not text_tag_found and gpt_response_text:
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å‡ºåŠ›å½¢å¼ã«åˆè‡´ã—ãªã„ãŒã€ä½•ã‚‰ã‹ã®ãƒ†ã‚­ã‚¹ãƒˆã¯ã‚ã‚‹å ´åˆ
        # ã“ã‚ŒãŒæ•´å½¢æ¸ˆã¿æ•´å½¢å¾ŒOCRã§ã‚ã‚‹ã¨ä»®å®šã™ã‚‹ï¼ˆãƒªã‚¹ã‚¯ã‚ã‚Šï¼‰
        # ãŸã ã—ã€"ã€åˆ†é¡ã€‘"ã‚„"ã€æ•´å½¢å¾ŒOCRã€‘"ã¨ã„ã†æ–‡å­—åˆ—è‡ªä½“ã‚’å«ã¾ãªã„ã“ã¨ã‚’ç¢ºèª
        if (
            "ã€åˆ†é¡ã€‘" not in gpt_response_text
            and "ã€æ•´å½¢å¾ŒOCRã€‘" not in gpt_response_text
        ):
            formatted_text = gpt_response_text  # ãã®ã¾ã¾æ•´å½¢å¾ŒOCRã¨ã™ã‚‹
            # final_classification ã¯ "æ¡ˆä»¶æŠ•ç¨¿" ã®ã¾ã¾
            print(
                "âš ï¸ GPTå‡ºåŠ›ã®ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã€‚å‡ºåŠ›ã‚’ãã®ã¾ã¾æ•´å½¢å¾ŒOCRã¨ã—ã¦æ‰±ã„ã¾ã™ï¼ˆåˆ†é¡ã¯ã€Œæ¡ˆä»¶æŠ•ç¨¿ã€ï¼‰ã€‚"
            )

    # ä»¥å‰ã® valid_classifications ãƒã‚§ãƒƒã‚¯ã¯ã€ã“ã®æ–°ã—ã„ãƒ­ã‚¸ãƒƒã‚¯ã§ã¯ä¸è¦ã«ãªã‚Šã¾ã™ã€‚
    # final_classification ã¯å¸¸ã« "è³ªå•å›ç­”" ã¾ãŸã¯ "æ¡ˆä»¶æŠ•ç¨¿" ã®ã„ãšã‚Œã‹ã«ãªã‚‹ãŸã‚ã€‚

    return {"classification": final_classification, "formatted_text": formatted_text}


def main():
    config_path = "config.json"
    try:
        config = load_config(config_path)
    except FileNotFoundError:
        print(f"ã‚¨ãƒ©ãƒ¼: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ« {config_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return
    except json.JSONDecodeError:
        print(f"ã‚¨ãƒ©ãƒ¼: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ« {config_path} ã®JSONå½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    api_key = config.get("openai_api_key")
    if not api_key:
        api_key = os.environ.get("OPENAI_API_KEY")  # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ã‚‚è©¦ã™
        if not api_key:
            print(
                f"ã‚¨ãƒ©ãƒ¼: {config_path}ã« 'openai_api_key' ã‚’è¿½åŠ ã™ã‚‹ã‹ã€ç’°å¢ƒå¤‰æ•° OPENAI_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
            )
            return

    prompt_file_path = "prompt.txt"
    try:
        with open(prompt_file_path, "r", encoding="utf-8") as f:
            prompt_text_from_file = f.read()
    except FileNotFoundError:
        print(
            f"ã‚¨ãƒ©ãƒ¼: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ« {prompt_file_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"
            "ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä½œæˆã—ã¦ãã ã•ã„ã€‚"
        )
        return
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: {prompt_file_path} ã®èª­ã¿è¾¼ã¿ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return

    scraped_post_text = ""
    scraped_ocr_text = ""
    input_data_path = (
        "tweet_for_gpt.json"  # scrape_and_save_tweets.py ãŒå‡ºåŠ›ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«
    )
    try:
        with open(input_data_path, "r", encoding="utf-8") as f_scraped_data:
            data = json.load(f_scraped_data)
            scraped_post_text = data.get("post_text", "")  # è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ç©ºæ–‡å­—
            scraped_ocr_text = data.get("ocr_text", "")  # è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ç©ºæ–‡å­—
        print(f"ğŸ“ {input_data_path} ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
    except FileNotFoundError:
        print(
            f"ã‚¨ãƒ©ãƒ¼: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ« {input_data_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"
            "scrape_and_save_tweets.py ã‚’å®Ÿè¡Œã—ã¦ã€å…ˆã«ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"
        )
        return  # ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„ã¨å‡¦ç†ã§ããªã„ã®ã§çµ‚äº†
    except json.JSONDecodeError:
        print(f"ã‚¨ãƒ©ãƒ¼: {input_data_path} ã®å†…å®¹ãŒæ­£ã—ã„JSONå½¢å¼ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: {input_data_path} ã®èª­ã¿è¾¼ã¿ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return

    # GPTã¸ã®å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’å‹•çš„ã«æ§‹ç¯‰
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†…ã§ {{æŠ•ç¨¿æœ¬æ–‡ã‚’ã“ã“ã«å…¥ã‚Œã¦ãã ã•ã„}} ã‚„ {{ç”»åƒã‹ã‚‰æŠ½å‡ºã—ãŸæ–‡å­—èµ·ã“ã—ã‚’ã“ã“ã«å…¥ã‚Œã¦ãã ã•ã„}}
    # ã¨ã„ã£ãŸãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’ä½¿ã£ã¦ã„ã‚‹å ´åˆã¯ã€ã“ã“ã§ç½®æ›ã™ã‚‹å½¢å¼ã‚‚è€ƒãˆã‚‰ã‚Œã‚‹ã€‚
    # ç¾åœ¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯æœ«å°¾ã«å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¾‹ãŒã‚ã‚Šã€ãã‚Œã«ç¶šã‘ã¦æœ¬æ–‡ã¨OCRã‚’æ¸¡ã™å½¢å¼ã€‚
    dynamic_input_text = f"""ã€æŠ•ç¨¿æœ¬æ–‡ã€‘:
{scraped_post_text}

ã€ç”»åƒOCRã€‘ï¼š
{scraped_ocr_text}
"""

    print("\n--- GPTã¸ã®å…¥åŠ› ---")
    # print(f"Prompt: \n{prompt_text_from_file}") # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒé•·ã„ã®ã§å…¨éƒ¨è¡¨ç¤ºã¯æ§ãˆã‚‹
    print(f"Input Text: \n{dynamic_input_text}")
    print("-------------------\n")

    gpt_raw_output = run_gpt_api(prompt_text_from_file, dynamic_input_text, api_key)

    if gpt_raw_output is None:
        print("âŒ GPTã‹ã‚‰ã®å¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™ã€‚")
        # ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã¯ gpt_output.json ã«ç©ºã¾ãŸã¯ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’å«ã‚ã¦ä¿å­˜ã™ã‚‹ã“ã¨ã‚‚æ¤œè¨
        error_output = {
            "classification": "ã‚¨ãƒ©ãƒ¼",
            "formatted_text": "GPT APIå‘¼ã³å‡ºã—å¤±æ•—",
        }
        output_file_path = "gpt_output.json"
        try:
            with open(output_file_path, "w", encoding="utf-8") as f_out:
                json.dump(error_output, f_out, ensure_ascii=False, indent=2)
            print(f"â„¹ï¸ ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’ {output_file_path} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
        except Exception as e_save:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼æƒ…å ±ã®ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e_save}")
        return

    print("=== GPT Raw Output ===")
    print(gpt_raw_output)
    print("====================\n")

    parsed_gpt_result = parse_gpt_output(gpt_raw_output)

    print("=== Parsed GPT Result ===")
    print(json.dumps(parsed_gpt_result, ensure_ascii=False, indent=2))
    print("=======================\n")

    output_file_path = "gpt_output.json"  # scrape_and_save_tweets.py ãŒèª­ã¿è¾¼ã‚€ãƒ•ã‚¡ã‚¤ãƒ«
    try:
        with open(output_file_path, "w", encoding="utf-8") as f_out:
            json.dump(parsed_gpt_result, f_out, ensure_ascii=False, indent=2)
        print(f"âœ… GPTã®å‡¦ç†çµæœã‚’ {output_file_path} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
    except Exception as e:
        print(f"âŒ GPTã®å‡¦ç†çµæœã®ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


if __name__ == "__main__":
    main()
