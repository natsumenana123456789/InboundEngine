import os
import sys
import re
# import cv2 # ocr_image å†…ã§ import numpy as np, cv2 ã•ã‚Œã¦ã„ã‚‹ã®ã§ä¸è¦ã‹ã‚‚
import time
import json
import shutil
import requests
import pytesseract
# import logging # logger ã‚’ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ã§å—ã‘å–ã‚‹ã®ã§ä¸è¦
from datetime import datetime, timedelta, timezone
from PIL import Image, ImageFilter, ImageEnhance
# from selenium import webdriver # webdriver_utils ã«ç§»è¡Œ
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
# from selenium.webdriver.chrome.options import Options # webdriver_utils ã«ç§»è¡Œ
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import (
    StaleElementReferenceException,
    NoSuchElementException,
    TimeoutException,
    ElementClickInterceptedException,
    WebDriverException
)
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload
from typing import List, Dict, Optional, Tuple, Any

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’sys.pathã«è¿½åŠ 
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
if PROJECT_ROOT not in sys.path:
    sys.path.append(PROJECT_ROOT)

# from utils.oauth_handler import OAuthHandler # TODO: OAuthHandler ã®å¿…è¦æ€§ã‚’ç¢ºèªã—ã€å¿…è¦ã§ã‚ã‚Œã°æ­£ã—ã„ãƒ‘ã‚¹ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹
from utils.webdriver_utils import get_driver, quit_driver
from utils.logger import setup_logger
import random
from notion_client import Client
from bs4 import BeautifulSoup
from config import config_loader

# åºƒå‘Šé™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
AD_KEYWORDS = [
    "r10.to",
    "ãµã‚‹ã•ã¨ç´ç¨",
    "ã‚«ãƒ¼ãƒ‰ãƒ­ãƒ¼ãƒ³",
    "ãŠé‡‘å€Ÿã‚Šã‚‰ã‚Œã‚‹",
    "ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚£ã‚¬ãƒ¬ãƒ¼ã‚¸",
    "UNEXT",
    "ã‚¨ã‚³ã‚ªã‚¯",
    "#PR",
    "æ¥½å¤©",
    "Amazon",
    "A8",
    "ã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆ",
    "å‰¯æ¥­",
    "bit.ly",
    "shp.ee",
    "t.co/",
]

class TweetExtractor:
    def __init__(self, bot_config: Dict[str, Any], parent_logger=None):
        self.config = bot_config # bot_config ã¯ curate_bot ã®è¨­å®šå…¨ä½“ã‚’æƒ³å®š
        # ãƒ­ã‚°é–¢é€£ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
        # bots/extract_tweets_bot/logs/
        # bots/extract_tweets_bot/logs/dom_errors/
        # bots/extract_tweets_bot/logs/screenshots/
        self.log_dir_name = self.config.get('log_dir_name', 'bots/extract_tweets_bot/logs')
        self.log_dir = os.path.join(PROJECT_ROOT, self.log_dir_name)
        self.error_log_dir = os.path.join(self.log_dir, 'dom_errors') # DOMã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆç”¨
        self.screenshots_dir = os.path.join(self.log_dir, 'screenshots') # ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆç”¨
        os.makedirs(self.log_dir, exist_ok=True)
        os.makedirs(self.error_log_dir, exist_ok=True)
        os.makedirs(self.screenshots_dir, exist_ok=True)

        self.logger = parent_logger if parent_logger else setup_logger(log_dir_name=self.log_dir_name, logger_name='TweetExtractor_default')
        self.driver: Optional[webdriver.Chrome] = None
        self.wait: Optional[WebDriverWait] = None
        self.logged_in_user: Optional[str] = None

        # ãƒ­ã‚°ã‚¤ãƒ³æƒ…å ±: bot_config (curate_botã®è¨­å®š) ã‹ã‚‰ç›´æ¥å–å¾—ã™ã‚‹
        active_account_id = self.config.get("active_curation_account_id")
        twitter_accounts_list = self.config.get("twitter_accounts", [])
        
        selected_account_info = None
        if active_account_id and twitter_accounts_list:
            for acc in twitter_accounts_list:
                if acc.get("account_id") == active_account_id:
                    selected_account_info = acc
                    break
        elif twitter_accounts_list: # active_id ãŒãªã„å ´åˆã€æœ€åˆã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’åˆ©ç”¨
            self.logger.warning(f"active_curation_account_id ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€twitter_accounts ã®æœ€åˆã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            selected_account_info = twitter_accounts_list[0]

        if selected_account_info:
            self.username = selected_account_info.get("username")
            self.password = selected_account_info.get("password")
            # å¿…è¦ã§ã‚ã‚Œã° email ã‚‚å–å¾—: self.email = selected_account_info.get("email")
        else:
            self.username = None
            self.password = None
            self.logger.error("æœ‰åŠ¹ãªTwitterã‚¢ã‚«ã‚¦ãƒ³ãƒˆæƒ…å ±ãŒ curate_bot ã®è¨­å®šã‹ã‚‰è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

        if not self.username or not self.password:
            self.logger.error("Twitterã®ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¾ãŸã¯ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å‡¦ç†ã‚’ç¶šè¡Œã§ãã¾ã›ã‚“ã€‚")
            raise ValueError("Twitterã®èªè¨¼æƒ…å ±ãŒ curate_bot ã®è¨­å®šã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

        self.logger.info(f"èª­ã¿è¾¼ã¾ã‚ŒãŸãƒ¦ãƒ¼ã‚¶ãƒ¼å: {self.username}")
        if self.password:
            self.logger.info(f"èª­ã¿è¾¼ã¾ã‚ŒãŸãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã®é•·ã•: {len(self.password)}")
        else:
            self.logger.warning("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

        # WebDriverè¨­å®š
        self.user_agent = self.config.get("user_agent", "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
        self.logger.info(f"ğŸ¤– ä½¿ç”¨ã™ã‚‹User-Agent: {self.user_agent}")
        # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ bots/extract_tweets_bot/.cache/chrome_profile_extract ã«å¤‰æ›´
        self.profile_path = self.config.get("chrome_profile_path", os.path.join(PROJECT_ROOT, "bots", "extract_tweets_bot", ".cache", "chrome_profile_extract"))
        self.logger.info(f"Chromeãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: {self.profile_path}")
        os.makedirs(os.path.dirname(self.profile_path), exist_ok=True) # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒãªã‘ã‚Œã°ä½œæˆ

        self._setup_driver()

    def _setup_driver(self):
        if self.driver:
            self.logger.info("WebDriverã¯æ—¢ã«åˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚")
            return
        try:
            self.driver = get_driver(user_agent=self.user_agent, profile_path=self.profile_path)
            self.logger.info("âœ… WebDriverã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
        except Exception as e:
            self.logger.error(f"âŒ WebDriverã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", exc_info=True)
            raise

    def login(self, target_username):
        if not self.driver:
            self.logger.error("âŒ WebDriverãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ­ã‚°ã‚¤ãƒ³ã§ãã¾ã›ã‚“ã€‚")
            self._setup_driver()
            if not self.driver:
                 raise RuntimeError("WebDriverã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

        # æ—¢ã«ãƒ­ã‚°ã‚¤ãƒ³æ¸ˆã¿ã‹ç¢ºèª (ä¾‹: URLã« /home ãŒå«ã¾ã‚Œã‚‹ã‹)
        # ã‚ˆã‚Šç¢ºå®Ÿãªã®ã¯ã€ãƒ­ã‚°ã‚¤ãƒ³å¾Œã«è¡¨ç¤ºã•ã‚Œã‚‹ã¹ãç‰¹å®šã®è¦ç´ ã®å­˜åœ¨ç¢ºèª
        try:
            if "/home" in self.driver.current_url.lower():
                self.logger.info("æ—¢ã«Twitterã«ãƒ­ã‚°ã‚¤ãƒ³æ¸ˆã¿ã§ã™ã€‚ãƒ­ã‚°ã‚¤ãƒ³å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                # ãƒ­ã‚°ã‚¤ãƒ³ãƒ¦ãƒ¼ã‚¶ãƒ¼åã‚’ç‰¹å®šã§ãã‚Œã° self.logged_in_user ã«ã‚»ãƒƒãƒˆã™ã‚‹ã“ã¨ã‚‚æ¤œè¨
                return
            # ã¾ãŸã¯ã€ç‰¹å®šã®è¦ç´ ãŒå­˜åœ¨ã™ã‚‹ã‹ã§åˆ¤æ–­ã™ã‚‹ (ä¾‹)
            # WebDriverWait(self.driver, 5).until(
            #     EC.presence_of_element_located((By.XPATH, "//a[@data-testid='AppTabBar_Home_Link']"))
            # )
            # self.logger.info("æ—¢ã«Twitterã«ãƒ­ã‚°ã‚¤ãƒ³æ¸ˆã¿ã§ã™ï¼ˆãƒ›ãƒ¼ãƒ ã‚¿ãƒ–ç¢ºèªï¼‰ã€‚ãƒ­ã‚°ã‚¤ãƒ³å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            # return
        except TimeoutException:
            self.logger.info("ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ã„ãªã„ã‚ˆã†ã§ã™ã€‚ãƒ­ã‚°ã‚¤ãƒ³å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
        except WebDriverException as e:
            self.logger.warning(f"ãƒ­ã‚°ã‚¤ãƒ³çŠ¶æ…‹ã®ç¢ºèªä¸­ã«WebDriverã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}ã€‚ãƒ­ã‚°ã‚¤ãƒ³å‡¦ç†ã‚’è©¦ã¿ã¾ã™ã€‚")

        if not self.username or not self.password:
            self.logger.error("âŒ Twitterã®ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¾ãŸã¯ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            raise ValueError("Twitterã®èªè¨¼æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")

        self.logger.info(f"Twitterã¸ã®ãƒ­ã‚°ã‚¤ãƒ³ã‚’é–‹å§‹ã—ã¾ã™: {self.username}")
        self.driver.get("https://twitter.com/login")
        time.sleep(random.uniform(2, 4)) # ãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿å¾…ã¡

        # ãƒ­ã‚°ã‚¤ãƒ³ãƒšãƒ¼ã‚¸è¡¨ç¤ºç›´å¾Œã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’ä¿å­˜
        screenshot_path = os.path.join(self.screenshots_dir, f"login_page_snapshot_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png")
        try:
            self.driver.save_screenshot(screenshot_path)
            self.logger.info(f"ãƒ­ã‚°ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {screenshot_path}")
        except Exception as e:
            self.logger.error(f"ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

        try:
            username_input = WebDriverWait(self.driver, 20).until( # å¾…æ©Ÿæ™‚é–“ã‚’10ç§’ã‹ã‚‰20ç§’ã«å»¶é•·
                EC.presence_of_element_located((By.CSS_SELECTOR, "input[name='text']"))
            )
            username_input.send_keys(self.username)
            self.logger.info(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼å {self.username} ã‚’å…¥åŠ›ã—ã¾ã—ãŸã€‚")

            next_button_xpath = "//span[contains(text(),'Next') or contains(text(),'æ¬¡ã¸')]"
            next_button = WebDriverWait(self.driver, 20).until(
                EC.element_to_be_clickable((By.XPATH, next_button_xpath))
            )
            next_button.click()
            self.logger.info("ã€Œæ¬¡ã¸ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¾ã—ãŸã€‚")
            time.sleep(random.uniform(1.5, 3))

            password_input = WebDriverWait(self.driver, 20).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "input[name='password']"))
            )
            password_input.send_keys(self.password)
            self.logger.info("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¾ã—ãŸã€‚")

            login_button_xpath = "//span[contains(text(),'Log in') or contains(text(),'ãƒ­ã‚°ã‚¤ãƒ³')]"
            login_button = WebDriverWait(self.driver, 20).until(
                EC.element_to_be_clickable((By.XPATH, login_button_xpath))
            )
            login_button.click()
            self.logger.info("ã€Œãƒ­ã‚°ã‚¤ãƒ³ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¾ã—ãŸã€‚")
            time.sleep(random.uniform(3, 5))

            if "home" in self.driver.current_url.lower():
                self.logger.info("âœ… Twitterã¸ã®ãƒ­ã‚°ã‚¤ãƒ³ã«æˆåŠŸã—ã¾ã—ãŸï¼")
            else:
                self.logger.warning(f"âš ï¸ ãƒ­ã‚°ã‚¤ãƒ³å¾Œã®URLãŒäºˆæœŸã—ãŸã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“: {self.driver.current_url}")
                if self.email: 
                    try:
                        email_confirm_input_xpath = "//input[@name='text' and @type='text']"
                        email_confirm_input = WebDriverWait(self.driver, 10).until(
                            EC.presence_of_element_located((By.XPATH, email_confirm_input_xpath))
                        )
                        if email_confirm_input.is_displayed():
                            self.logger.info(f"è¿½åŠ ã®ç¢ºèªã¨ã—ã¦ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ {self.email} ã®å…¥åŠ›ã‚’è©¦ã¿ã¾ã™ã€‚")
                            email_confirm_input.send_keys(self.email)
                            next_button_after_email = WebDriverWait(self.driver, 20).until(
                                EC.element_to_be_clickable((By.XPATH, next_button_xpath))
                            )
                            next_button_after_email.click()
                            self.logger.info("ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹å…¥åŠ›å¾Œã®ã€Œæ¬¡ã¸ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¾ã—ãŸã€‚")
                            time.sleep(random.uniform(3,5))
                            if "home" in self.driver.current_url.lower():
                                self.logger.info("âœ… ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã«ã‚ˆã‚‹è¿½åŠ ç¢ºèªå¾Œã€ãƒ­ã‚°ã‚¤ãƒ³ã«æˆåŠŸã—ã¾ã—ãŸï¼")
                            else:
                                self.logger.error(f"âŒ ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹å…¥åŠ›å¾Œã‚‚ãƒ­ã‚°ã‚¤ãƒ³ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ç¾åœ¨ã®URL: {self.driver.current_url}")
                                raise Exception("ãƒ­ã‚°ã‚¤ãƒ³ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®è¿½åŠ ç¢ºèªã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                        else: # is_displayed ãŒ False ã®å ´åˆ
                            self.logger.error("âŒ ãƒ¡ãƒ¼ãƒ«ç¢ºèªå…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸãŒã€è¡¨ç¤ºã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                            raise Exception("ãƒ­ã‚°ã‚¤ãƒ³ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®è¿½åŠ ç¢ºèª(ãƒ¡ãƒ¼ãƒ«)è¦ç´ éè¡¨ç¤ºã€‚")
                    except TimeoutException:
                        self.logger.error("âŒ ãƒ¡ãƒ¼ãƒ«ç¢ºèªå…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼‰ã€‚")
                        raise Exception("ãƒ­ã‚°ã‚¤ãƒ³ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®è¿½åŠ ç¢ºèª(ãƒ¡ãƒ¼ãƒ«)è¦ç´ ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã€‚")
                    except Exception as e_confirm:
                        self.logger.error(f"âŒ ãƒ­ã‚°ã‚¤ãƒ³ä¸­ã®ãƒ¡ãƒ¼ãƒ«ç¢ºèªå‡¦ç†ã§äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e_confirm}")
                        raise # å…ƒã®ä¾‹å¤–ã‚’å†é€å‡º
                else: # self.email ãŒãªã„å ´åˆ
                    self.logger.error("âŒ ãƒ­ã‚°ã‚¤ãƒ³ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹æƒ…å ±ãªã—ï¼‰ã€‚")
                    raise Exception("ãƒ­ã‚°ã‚¤ãƒ³ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å¤±æ•—ã€ãƒ¡ãƒ¼ãƒ«æƒ…å ±ãªã—ã€‚")

        except TimeoutException as te:
            self.logger.error(f"âŒ ãƒ­ã‚°ã‚¤ãƒ³å‡¦ç†ä¸­ã«ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãŒç™ºç”Ÿã—ã¾ã—ãŸ: {te}", exc_info=True)
            self._save_dom_error_log(self.driver.page_source, "login_timeout")
            raise
        except Exception as e:
            self.logger.error(f"âŒ ãƒ­ã‚°ã‚¤ãƒ³å‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", exc_info=True)
            self._save_dom_error_log(self.driver.page_source, "login_general_error")
            raise

    def extract_tweets(self, username, max_tweets, globally_processed_ids):
        if not self.driver:
            self.logger.error("âŒ WebDriverãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ„ã‚¤ãƒ¼ãƒˆã‚’åé›†ã§ãã¾ã›ã‚“ã€‚")
            return []
        
        self.logger.info(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ @{username} ã®ãƒ„ã‚¤ãƒ¼ãƒˆåé›†ã‚’é–‹å§‹ã—ã¾ã™ (æœ€å¤§ {max_tweets} ä»¶)ã€‚")
        # ä¾‹: if self.bot_config.get('extraction_method') == 'api': 
        #    # (self.api_client ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã‚‹ã‹ç­‰ã®ãƒã‚§ãƒƒã‚¯ã‚‚å¿…è¦)
        #    return self.api_client.fetch_tweets_by_username_app_context(username, max_tweets)

        target_url = f"https://twitter.com/{username}"
        self.driver.get(target_url)
        self.logger.info(f"ãƒšãƒ¼ã‚¸ {target_url} ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¾ã—ãŸã€‚")
        time.sleep(random.uniform(4, 6)) # ãƒšãƒ¼ã‚¸ã®èª­ã¿è¾¼ã¿ã‚’å¾…ã¤æ™‚é–“ã‚’å°‘ã—å»¶é•·

        # ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ãƒšãƒ¼ã‚¸è¡¨ç¤ºç›´å¾Œã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’ä¿å­˜
        profile_page_screenshot_path = os.path.join(self.screenshots_dir, f"profile_page_snapshot_{username}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png")
        try:
            self.driver.save_screenshot(profile_page_screenshot_path)
            self.logger.info(f"ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ãƒšãƒ¼ã‚¸ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {profile_page_screenshot_path}")
        except Exception as e:
            self.logger.error(f"ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ãƒšãƒ¼ã‚¸ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

        tweets_data = []
        tweet_ids_on_page = set()
        last_height = self.driver.execute_script("return document.body.scrollHeight")
        consecutive_scroll_fails = 0

        self.temp_media_dir = os.path.join(os.path.dirname(__file__), "temp_media", datetime.now().strftime("%Y%m%d_%H%M%S"))
        os.makedirs(self.temp_media_dir, exist_ok=True)
        self.logger.info(f"ä¸€æ™‚ãƒ¡ãƒ‡ã‚£ã‚¢ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ: {self.temp_media_dir}")

        try:
            while len(tweets_data) < max_tweets:
                articles = self.driver.find_elements(By.XPATH, "//article[@data-testid='tweet']")
                if not articles:
                    self.logger.info("ãƒ„ã‚¤ãƒ¼ãƒˆè¦ç´ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒšãƒ¼ã‚¸ã®çµ‚ç«¯ã‹ã€æ§‹é€ ãŒå¤‰ã‚ã£ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
                    # DOMã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’ä¿å­˜
                    self._save_dom_error_log(self.driver.page_source, f"no_tweets_found_{username}")
                    if self.driver.find_elements(By.XPATH, "//*[contains(text(), 'Retry')]"): 
                        self.logger.warning("ã€Œå†è©¦è¡Œã€ãƒœã‚¿ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã‚’è©¦ã¿ã¾ã™ã€‚")
                        self.driver.refresh()
                        time.sleep(random.uniform(3,5))
                        continue 
                    break 

                new_tweets_found_on_this_scroll = False
                for article in articles:
                    if len(tweets_data) >= max_tweets:
                        break
                    
                    try:
                        tweet_id = self.extract_tweet_id(article)
                        if not tweet_id:
                            self.logger.warning("ãƒ„ã‚¤ãƒ¼ãƒˆIDãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã“ã®è¦ç´ ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                            continue

                        if tweet_id in tweet_ids_on_page or tweet_id in globally_processed_ids:
                            continue
                        
                        tweet_ids_on_page.add(tweet_id)
                        new_tweets_found_on_this_scroll = True

                        tweet_text_element = article.find_element(By.XPATH, ".//div[@data-testid='tweetText']")
                        tweet_text = tweet_text_element.text if tweet_text_element else ""
                        
                        if self.is_ad_post(tweet_text):
                            self.logger.info(f"åºƒå‘Šã¨æ€ã‚ã‚Œã‚‹ãƒ„ã‚¤ãƒ¼ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—: {tweet_text[:50]}...")
                            continue

                        timestamp_element = article.find_element(By.XPATH, ".//time")
                        timestamp_str = timestamp_element.get_attribute("datetime") if timestamp_element else ""
                        
                        author_name = ""
                        author_username = ""
                        try: 
                            author_elements = article.find_elements(By.XPATH, ".//div[@data-testid='User-Name']//a")
                            if len(author_elements) >= 2: 
                                author_name = author_elements[0].text
                                author_username = author_elements[1].text.lstrip('@')
                        except Exception as e_author:
                            self.logger.warning(f"ãƒ„ã‚¤ãƒ¼ãƒˆ {tweet_id} ã®è‘—è€…æƒ…å ±å–å¾—ã«å¤±æ•—: {e_author}")

                        media_urls = []
                        media_elements = article.find_elements(By.XPATH, ".//div[@data-testid='tweetPhoto']//img | .//div[contains(@data-testid, 'videoPlayer')]")
                        
                        local_media_paths = [] 

                        for media_elem in media_elements:
                            media_type = "unknown"
                            media_src = None
                            if media_elem.tag_name == "img":
                                media_type = "photo"
                                media_src = media_elem.get_attribute("src")
                                if media_src and "format=jpg" in media_src: 
                                    media_src = media_src.split("&name=")[0] + "&name=large" 
                            elif "videoPlayer" in media_elem.get_attribute("data-testid"):
                                media_type = "video"
                                try:
                                    video_poster_img = media_elem.find_element(By.XPATH, ".//video")
                                    media_src = video_poster_img.get_attribute("poster") 
                                    if not media_src: 
                                        source_tag = media_elem.find_element(By.XPATH, ".//video/source")
                                        media_src = source_tag.get_attribute("src") 
                                        self.logger.warning(f"å‹•ç”»ã‚½ãƒ¼ã‚¹ãŒblob URLã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™: {media_src}")
                                except NoSuchElementException:
                                    self.logger.warning(f"ãƒ„ã‚¤ãƒ¼ãƒˆ {tweet_id} ã®å‹•ç”»ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼ã‹ã‚‰ãƒ¡ãƒ‡ã‚£ã‚¢ã‚½ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                                
                            if media_src:
                                media_urls.append({"type": media_type, "url": media_src})
                                downloaded_path = self._download_media(media_src, tweet_id, media_type)
                                if downloaded_path:
                                    local_media_paths.append(downloaded_path)
                        
                        ocr_text_combined = ""
                        if self.bot_config.get("enable_ocr", False) and local_media_paths:
                            for img_path in local_media_paths:
                                if img_path.lower().endswith((".png", ".jpg", ".jpeg")): 
                                    try:
                                        ocr_result = self.ocr_image(img_path)
                                        if ocr_result:
                                            ocr_text_combined += ocr_result + "\n"
                                    except Exception as e_ocr:
                                        self.logger.error(f"ç”»åƒ {img_path} ã®OCRå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e_ocr}")
                            if ocr_text_combined:
                                self.logger.info(f"ãƒ„ã‚¤ãƒ¼ãƒˆ {tweet_id} ã®ãƒ¡ãƒ‡ã‚£ã‚¢ã‹ã‚‰OCRãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—: {ocr_text_combined[:50]}...")

                        tweet_data = {
                            "id": tweet_id,
                            "text": tweet_text,
                            "timestamp": timestamp_str,
                            "author_name": author_name,
                            "author_username": author_username,
                            "media_urls": media_urls, 
                            "local_media_paths": local_media_paths, 
                            "ocr_text": ocr_text_combined.strip() if ocr_text_combined else None,
                            "raw_html_element": article.get_attribute('outerHTML') 
                        }
                        tweets_data.append(tweet_data)
                        self.logger.info(f"åé›†æ¸ˆã¿ãƒ„ã‚¤ãƒ¼ãƒˆæ•°: {len(tweets_data)} / {max_tweets}")

                    except StaleElementReferenceException:
                        self.logger.warning("StaleElementReferenceExceptionãŒç™ºç”Ÿã€‚è¦ç´ ãŒå†æç”»ã•ã‚ŒãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™ã€‚")
                        break 
                    except NoSuchElementException as nse:
                        self.logger.warning(f"ãƒ„ã‚¤ãƒ¼ãƒˆè¦ç´ ã®è§£æä¸­ã«NoSuchElementException: {nse}ã€‚ã“ã®ãƒ„ã‚¤ãƒ¼ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                        continue 
                    except Exception as e_article:
                        self.logger.error(f"è¨˜äº‹è¦ç´ ã®å‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e_article}", exc_info=True)
                        continue 
                
                if not new_tweets_found_on_this_scroll and articles: 
                    self.logger.info("ä»Šå›ã®ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã§ã¯æ–°ã—ã„ãƒ„ã‚¤ãƒ¼ãƒˆã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                    consecutive_scroll_fails += 1
                    if consecutive_scroll_fails >= 3: 
                        self.logger.info("æ–°ã—ã„ãƒ„ã‚¤ãƒ¼ãƒˆãŒé€£ç¶šã—ã¦è¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€åé›†ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                        break
                else:
                    consecutive_scroll_fails = 0 

                self.logger.debug("ãƒšãƒ¼ã‚¸ã‚’ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã—ã¾ã™...")
                self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(random.uniform(2, 4)) 

                new_height = self.driver.execute_script("return document.body.scrollHeight")
                if new_height == last_height: 
                    self.logger.info("ãƒšãƒ¼ã‚¸ã®é«˜ã•ãŒå¤‰ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã“ã‚Œä»¥ä¸Šã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã§ããªã„ã‹ã€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                    consecutive_scroll_fails +=1 
                    if consecutive_scroll_fails >=3:
                         self.logger.info("ãƒšãƒ¼ã‚¸ã®é«˜ã•ãŒé€£ç¶šã—ã¦å¤‰ã‚ã‚‰ãªã„ãŸã‚ã€åé›†ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                         break
                else:
                    consecutive_scroll_fails = 0 
                last_height = new_height

        except Exception as e:
            self.logger.error(f"ãƒ„ã‚¤ãƒ¼ãƒˆåé›†ã®ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", exc_info=True)
        finally:
            pass 

        self.logger.info(f"åé›†å®Œäº†ã€‚åˆè¨ˆ {len(tweets_data)} ä»¶ã®ãƒ„ã‚¤ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸã€‚")
        return tweets_data

    def cleanup(self):
        if self.driver:
            quit_driver(self.driver)
            self.driver = None
            self.logger.info("WebDriverã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")

    def _save_dom_error_log(self, element_html, error_identifier):
        log_dir = os.path.join(os.path.dirname(__file__), "logs", "dom_errors")
        os.makedirs(log_dir, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
        filename = os.path.join(log_dir, f"error_dom_{error_identifier}_{timestamp}.html")
        try:
            with open(filename, "w", encoding="utf-8") as f:
                f.write(element_html)
            self.logger.info(f"ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã®DOMã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filename}")
        except Exception as e:
            self.logger.error(f"DOMã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã®ä¿å­˜ã«å¤±æ•—: {e}")

    def extract_tweet_id(self, article_element):
        """<article>è¦ç´ ã‹ã‚‰ãƒ„ã‚¤ãƒ¼ãƒˆIDã‚’æŠ½å‡ºã™ã‚‹ã€‚
        ãƒ„ã‚¤ãƒ¼ãƒˆIDã¯é€šå¸¸ã€ãƒ„ã‚¤ãƒ¼ãƒˆã¸ã®ãƒ‘ãƒ¼ãƒãƒªãƒ³ã‚¯URLã«å«ã¾ã‚Œã‚‹æœ€å¾Œã®æ•°å€¤éƒ¨åˆ†ã€‚
        ä¾‹: /username/status/1234567890
        """
        try:
            links_with_status = article_element.find_elements(By.XPATH, ".//a[contains(@href, '/status/')]")
            for link_element in links_with_status:
                href = link_element.get_attribute("href")
                if href:
                    match = re.search(r"/status/(\d+)", href)
                    if match:
                        tweet_id = match.group(1)
                        return tweet_id
            self.logger.warning(f"è¨˜äº‹è¦ç´ å†…ã‹ã‚‰ãƒ„ã‚¤ãƒ¼ãƒˆIDã‚’å«ã‚€ãƒªãƒ³ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚HTML: {article_element.get_attribute('outerHTML')[:500]}")
            return None
        except Exception as e:
            self.logger.error(f"ãƒ„ã‚¤ãƒ¼ãƒˆIDã®æŠ½å‡ºä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return None

    def ocr_image(self, image_path):
        if not os.path.exists(image_path):
            self.logger.error(f"OCRå¯¾è±¡ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {image_path}")
            return None
        try:
            img = Image.open(image_path)
            img = img.convert('L')  
            img = img.filter(ImageFilter.MedianFilter()) 
            enhancer = ImageEnhance.Contrast(img)
            img = enhancer.enhance(2) 
            text = pytesseract.image_to_string(img, lang='jpn+eng')
            self.logger.info(f"ç”»åƒ {image_path} ã‹ã‚‰OCRãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã—ã¾ã—ãŸ: {text[:50]}...")
            return text
        except FileNotFoundError: 
             self.logger.error("âŒ Tesseract OCRã‚¨ãƒ³ã‚¸ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‘ã‚¹ãŒé€šã£ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
             return None
        except Exception as e:
            self.logger.error(f"ç”»åƒ {image_path} ã®OCRå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return None

    def is_ad_post(self, text):
        text_lower = text.lower()
        for keyword in AD_KEYWORDS:
            if keyword.lower() in text_lower:
                return True
        return False

    def _download_media(self, media_url, tweet_id, media_type="photo"):
        if not media_url:
            return None
        
        try:
            filename_base = f"{tweet_id}_{os.path.basename(media_url).split('?')[0]}"
            response_head = requests.head(media_url, timeout=10, allow_redirects=True)
            content_type = response_head.headers.get('Content-Type')
            extension = ".jpg" 
            if content_type:
                if "image/jpeg" in content_type: extension = ".jpg"
                elif "image/png" in content_type: extension = ".png"
                elif "image/gif" in content_type: extension = ".gif"
                elif "video/mp4" in content_type: extension = ".mp4"
            
            if not content_type or extension == ".jpg": 
                 url_path = media_url.split('?')[0]
                 if url_path.endswith(".png"): extension = ".png"
                 elif url_path.endswith(".gif"): extension = ".gif"
                 elif url_path.endswith(".mp4"): extension = ".mp4"

            filename = filename_base + extension
            local_filepath = os.path.join(self.temp_media_dir, filename)

            self.logger.info(f"ãƒ¡ãƒ‡ã‚£ã‚¢ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­: {media_url} -> {local_filepath}")
            response = requests.get(media_url, stream=True, timeout=20)
            response.raise_for_status()
            with open(local_filepath, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)
            self.logger.info(f"ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {local_filepath}")
            return local_filepath
        except requests.exceptions.RequestException as e:
            self.logger.error(f"ãƒ¡ãƒ‡ã‚£ã‚¢ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•— ({media_url}): {e}")
            return None
        except Exception as e_dl:
            self.logger.error(f"ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã®ä¸€èˆ¬ã‚¨ãƒ©ãƒ¼ ({media_url}): {e_dl}", exc_info=True)
            return None

    def _upload_to_drive_and_get_link(self, local_filepath, tweet_id):
        self.logger.warning("_upload_to_drive_and_get_link ã¯ compile_bot ã¾ãŸã¯ NotionWriter ã§ã®å®Ÿè£…ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚ç¾åœ¨ã¯ä½¿ã‚ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return None